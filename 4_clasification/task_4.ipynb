{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES_DIR = '../Dane/wiki_train/'\n",
    "TEST_FILES_DIR = '../Dane/wiki_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_df(data_part, tagger, part_of_speech):\n",
    "    df = pd.DataFrame(columns=['text', 'label'])\n",
    "    \n",
    "    for file in sorted(os.listdir(data_part)):\n",
    "        if file.endswith(tagger+'.csv'):\n",
    "            file_text = ''\n",
    "            file_class = file.split('_')[0]\n",
    "\n",
    "            with open(data_part+file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                line = line.replace('\\n', '')\n",
    "                if line.endswith(part_of_speech):\n",
    "                    #print(line)\n",
    "                    word = line.split(',')[1]\n",
    "                    file_text = file_text+' '+word if file_text != '' else file_text+word\n",
    "\n",
    "            df = df.append({'text': file_text, \n",
    "                            'label': file_class}, ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def train_test_split(df_train, df_test, max_features=10000):\n",
    "    cv = CountVectorizer(max_features=max_features)\n",
    "    \n",
    "    X_train = df_train.text.tolist()\n",
    "    X_train = cv.fit_transform(X_train).toarray()\n",
    "    y_train = df_train.label.tolist()\n",
    "\n",
    "    X_test = df_test.text.tolist()\n",
    "    X_test = cv.transform(X_test).toarray()\n",
    "    y_test = df_test.label.tolist()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggers = ['morphoDita', 'wcrft2', 'krnnt']\n",
    "parts_of_speech = ['noun', 'adjective', 'verb']\n",
    "max_features_list = [1000, 10000, 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with params: tagger: morphoDita - part of speech: noun - max features: 1000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: adjective - max features: 1000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: verb - max features: 1000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: noun - max features: 1000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: adjective - max features: 1000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: verb - max features: 1000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: noun - max features: 1000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: adjective - max features: 1000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: verb - max features: 1000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: noun - max features: 10000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: adjective - max features: 10000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: verb - max features: 10000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: noun - max features: 10000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: adjective - max features: 10000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: verb - max features: 10000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: noun - max features: 10000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: adjective - max features: 10000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: verb - max features: 10000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: noun - max features: 100000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: adjective - max features: 100000 ...\n",
      "Classification with params: tagger: morphoDita - part of speech: verb - max features: 100000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: noun - max features: 100000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: adjective - max features: 100000 ...\n",
      "Classification with params: tagger: wcrft2 - part of speech: verb - max features: 100000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: noun - max features: 100000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: adjective - max features: 100000 ...\n",
      "Classification with params: tagger: krnnt - part of speech: verb - max features: 100000 ...\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame(columns=['max_features', 'tagger', 'part_of_speech', 'accuracy', 'time'])\n",
    "\n",
    "for max_features in max_features_list:\n",
    "    for tagger in taggers:\n",
    "        for part_of_speech in parts_of_speech:\n",
    "            print('Classification with params: tagger:', tagger, \n",
    "                  '- part of speech:', part_of_speech, \n",
    "                  '- max features:', max_features, '...')\n",
    "\n",
    "            start_timer = time.time()\n",
    "            df_train = files_to_df(data_part=TRAIN_FILES_DIR, \n",
    "                                   tagger=tagger, \n",
    "                                   part_of_speech=part_of_speech)\n",
    "\n",
    "            df_test = files_to_df(data_part=TEST_FILES_DIR, \n",
    "                                  tagger=tagger, \n",
    "                                  part_of_speech=part_of_speech)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df_train=df_train, \n",
    "                                                                df_test=df_test, \n",
    "                                                                max_features=max_features)\n",
    "\n",
    "            # Naive Bayes\n",
    "            classifier = GaussianNB()\n",
    "            classifier.fit(X_train, y_train)\n",
    "\n",
    "            # Predict Class\n",
    "            y_pred = classifier.predict(X_test)\n",
    "\n",
    "            # Accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            exec_time = time.time() - start_timer\n",
    "\n",
    "            #print('Tagger:', tagger, \n",
    "            #      '- Part of speech:', part_of_speech, \n",
    "            #      '\\n\\tAccuracy:', accuracy, '\\n')\n",
    "\n",
    "            df_res = df_res.append({'max_features': max_features, \n",
    "                                    'tagger': tagger, \n",
    "                                    'part_of_speech': part_of_speech, \n",
    "                                    'accuracy': accuracy, \n",
    "                                    'time': exec_time}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>tagger</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.557738</td>\n",
       "      <td>22.851148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.453776</td>\n",
       "      <td>20.554830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.278361</td>\n",
       "      <td>21.463108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.544531</td>\n",
       "      <td>25.685656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.454453</td>\n",
       "      <td>21.767061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.275652</td>\n",
       "      <td>22.459691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.560786</td>\n",
       "      <td>37.497144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.444633</td>\n",
       "      <td>20.976613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.274297</td>\n",
       "      <td>20.357028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.759228</td>\n",
       "      <td>34.240557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.602777</td>\n",
       "      <td>32.625806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>28.261333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.741619</td>\n",
       "      <td>34.037343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.595665</td>\n",
       "      <td>32.197036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>30.373978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.767355</td>\n",
       "      <td>39.086552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.596004</td>\n",
       "      <td>34.049288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.369455</td>\n",
       "      <td>32.430375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.766678</td>\n",
       "      <td>65.816837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.605147</td>\n",
       "      <td>33.528471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100000</td>\n",
       "      <td>morphoDita</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>28.225787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.754487</td>\n",
       "      <td>56.246981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.595665</td>\n",
       "      <td>32.864610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100000</td>\n",
       "      <td>wcrft2</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>28.376874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>noun</td>\n",
       "      <td>0.799865</td>\n",
       "      <td>161.063902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>adjective</td>\n",
       "      <td>0.596681</td>\n",
       "      <td>54.813931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100000</td>\n",
       "      <td>krnnt</td>\n",
       "      <td>verb</td>\n",
       "      <td>0.369455</td>\n",
       "      <td>28.245855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_features      tagger part_of_speech  accuracy        time\n",
       "0           1000  morphoDita           noun  0.557738   22.851148\n",
       "1           1000  morphoDita      adjective  0.453776   20.554830\n",
       "2           1000  morphoDita           verb  0.278361   21.463108\n",
       "3           1000      wcrft2           noun  0.544531   25.685656\n",
       "4           1000      wcrft2      adjective  0.454453   21.767061\n",
       "5           1000      wcrft2           verb  0.275652   22.459691\n",
       "6           1000       krnnt           noun  0.560786   37.497144\n",
       "7           1000       krnnt      adjective  0.444633   20.976613\n",
       "8           1000       krnnt           verb  0.274297   20.357028\n",
       "9          10000  morphoDita           noun  0.759228   34.240557\n",
       "10         10000  morphoDita      adjective  0.602777   32.625806\n",
       "11         10000  morphoDita           verb  0.368100   28.261333\n",
       "12         10000      wcrft2           noun  0.741619   34.037343\n",
       "13         10000      wcrft2      adjective  0.595665   32.197036\n",
       "14         10000      wcrft2           verb  0.354893   30.373978\n",
       "15         10000       krnnt           noun  0.767355   39.086552\n",
       "16         10000       krnnt      adjective  0.596004   34.049288\n",
       "17         10000       krnnt           verb  0.369455   32.430375\n",
       "18        100000  morphoDita           noun  0.766678   65.816837\n",
       "19        100000  morphoDita      adjective  0.605147   33.528471\n",
       "20        100000  morphoDita           verb  0.368100   28.225787\n",
       "21        100000      wcrft2           noun  0.754487   56.246981\n",
       "22        100000      wcrft2      adjective  0.595665   32.864610\n",
       "23        100000      wcrft2           verb  0.354893   28.376874\n",
       "24        100000       krnnt           noun  0.799865  161.063902\n",
       "25        100000       krnnt      adjective  0.596681   54.813931\n",
       "26        100000       krnnt           verb  0.369455   28.245855"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_res.to_csv('out/task_4_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
